spliced_list[-1] <-
seq(max(spliced_list[[1]]),
length(thread_ids),
175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
spliced_list <- list()
spliced_list[[1]] <-
1:(rl[["remaining"]] - 720 - 5)
spliced_list <-
append(
seq(max(spliced_list[[1]]),
length(thread_ids),
175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character()))
spliced_list <-
append(spliced_list,
seq(max(spliced_list[[1]]),
length(thread_ids),
175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character()))
spliced_list
spliced_list <- list()
spliced_list[[1]] <-
1:(rl[["remaining"]] - 720 - 5)
spliced_list <-
append(spliced_list,
seq(max(spliced_list[[1]]),
length(thread_ids),
175)
%>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character()))
spliced_list
spliced_list <- list()
spliced_list[[1]] <-
1:(rl[["remaining"]] - 720 - 5)
spliced_list <-
append(spliced_list,
seq(max(spliced_list[[1]]),
length(thread_ids),
175))
spliced_list <-
spliced_list %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character()))
spliced_list
spliced_list <- list()
spliced_list[[1]] <-
1:(rl[["remaining"]] - 720 - 5)
spliced_list <-
append(spliced_list,
seq(max(spliced_list[[1]]),
length(thread_ids),
175) %>%
map(~.x + 1:175))
spliced_list
spliced_list <-
spliced_list %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character()))
spliced_list <-
spliced_list %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
spliced_list
aa <- rtweet::get_favorites(df_tls$user_id %>% unique() %>% .[1:5])
rl <- rtweet::rate_limit("get_timeline")
rl
rl <- rtweet::rate_limit("get_favorites")
rl
scrape_favs2test <- function(ids, save_res = TRUE) {
safe_fav <- purrr::possibly(rtweet::get_favorites, otherwise = tibble())
l <- vector("list", length(ids))
for (i in 1:length(l)) {
rl <- rtweet::rate_limit("get_favorites")
if (rl[["remaining"]] <= 2) {
df_favs <- l %>% dplyr::bind_rows()
return(df_favs)
}
l[[i]] <- safe_fav(ids[[i]], n = 320, since_id = main_status_id)
print(paste0("Index: ", i,
"; Scraped ", nrow(l[[i]]),
" tweets. Remaining: ", rl[["remaining"]]))
}
}
favtest <- scrape_favs2(thread_ids)
rl <- rtweet::rate_limit("get_favorites")
aa <- rtweet::get_timelines(thread_ids %>% .[1:175])
rl
rl <- rtweet::rate_limit("get_timeline")
rl
aa$user_id %>% unique()
set_colnames(1:2)
set_names(1:2)
1:2 %>% set_colnames()
magrittr::set_colnames(1:2)
1:2 %>% magrittr::set_colnames()
df <- tribble(
~date,        ~fruit,   ~cost, ~sales,
"2020-03-01", "Apple",     NA,     NA,
"2020-03-01", "Banana",     5,      3,
"2020-03-02", "Apple",     10,      4,
"2020-03-02", "Banana",    NA,      1
)
# Change a data frame's column names within a pipeline!
df %>%
group_by(date) %>%
summarise(sales = sum(sales, na.rm = TRUE)) %>%
magrittr::set_colnames(c("Date", "Total Sales"))
df <- tribble(
~date,        ~fruit,   ~cost, ~sales,
"2020-03-01", "Apple",     NA,     NA,
"2020-03-01", "Banana",     5,      3,
"2020-03-02", "Apple",     10,      4,
"2020-03-02", "Banana",    NA,      1
)
# Change a data frame's column names within a pipeline!
df %>%
group_by(date) %>%
summarise(sales = sum(sales, na.rm = TRUE)) %>%
set_names(c("Date", "Total Sales"))
c("a", "b") %>%
set_names()
c("a", "b") %>% set_names()
ddd <- purrr::possibly(rtweet::get_favorites, otherwise = ddd)
rl <- rtweet::rate_limit("get_timeline")
aa <- rtweet::get_timelines(thread_ids[1:175])
rl
rl <- rtweet::rate_limit("get_favorites")
favtest <- scrape_favs2(thread_ids)
rl
rl <- rtweet::rate_limit("get_favorites")
rl
rl <- rtweet::rate_limit("get_favorites")
rl
rl <- rtweet::rate_limit("get_timeline")
rl
scrape_timelines <- function(thread_ids, save_res = TRUE) {
safe_tl <- purrr::possibly(rtweet::get_timelines, otherwise = tibble())
# l <- vector("list", length(thread_ids))
# for (i in 1:length(l)) {
#   rl <- rtweet::rate_limit("get_timeline")
#   if (rl[["remaining"]] <= 2) {
#     print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#     Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
#   }
#   l[[i]] <- safe_tl(thread_ids[[i]], n = 3200, since_id = main_status_id)
#   print(paste0("Index: ", i,
#                "; Scraped ", nrow(l[[i]]),
#                " tweets. Remaining: ", rl[["remaining"]]))
# }
# df_favs <- l %>% dplyr::bind_rows()
# # if (save_res == TRUE) {
# #   save_name <- paste0(df_main_status$screen_name,
# #                       "_",
# #                       str_sub(df_main_status$text, end = 15),
# #                       "_favs.rds")
# #   saveRDS(df_favs, save_name)
# # }
# df_favs
rl <- rtweet::rate_limit("get_timeline")
if (rl[["remaining"]] != 900) Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
spliced_list <-
seq(0, length(thread_ids), 175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
# if (rl[["remaining"]] <= 2) {
#   print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#   Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# }
load_slowly <- function(thread_ids, index) {
df <- safe_tl(thread_ids,
since_id = main_status_id,
n = 3200)
rl <- rtweet::rate_limit("get_timeline")
print(paste0("Index: ", index,
"Scraped ", nrow(df),
" tweets. Remaining: ", rl[["remaining"]]))
Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# print(df)
df
}
spliced_list <- seq(0, length(thread_ids), 175) %>% map(~.x + 1:175)
l_tls <-
spliced_list %>%
imap(~load_slowly(.x, .y))
# if (save_res == TRUE) {
#   save_name <- paste0(df_main_status$screen_name,
#                       "_",
#                       str_sub(df_main_status$text, end = 15),
#                       "_tls.rds")
#   saveRDS(l_tls, save_name)
# }
l_tls %>% bind_rows()
}
aa <- scrape_timelines(thread_ids[1:176])
warnings()
rl <- rtweet::rate_limit("get_timeline")
rl
scrape_timelines <- function(thread_ids, save_res = TRUE) {
safe_tl <- purrr::possibly(rtweet::get_timelines, otherwise = tibble())
# l <- vector("list", length(thread_ids))
# for (i in 1:length(l)) {
#   rl <- rtweet::rate_limit("get_timeline")
#   if (rl[["remaining"]] <= 2) {
#     print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#     Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
#   }
#   l[[i]] <- safe_tl(thread_ids[[i]], n = 3200, since_id = main_status_id)
#   print(paste0("Index: ", i,
#                "; Scraped ", nrow(l[[i]]),
#                " tweets. Remaining: ", rl[["remaining"]]))
# }
# df_favs <- l %>% dplyr::bind_rows()
# # if (save_res == TRUE) {
# #   save_name <- paste0(df_main_status$screen_name,
# #                       "_",
# #                       str_sub(df_main_status$text, end = 15),
# #                       "_favs.rds")
# #   saveRDS(df_favs, save_name)
# # }
# df_favs
rl <- rtweet::rate_limit("get_timeline")
if (rl[["remaining"]] != 900) Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
spliced_list <-
seq(0, length(thread_ids), 175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
# if (rl[["remaining"]] <= 2) {
#   print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#   Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# }
load_slowly <- function(thread_ids, index) {
df <- safe_tl(thread_ids,
since_id = main_status_id,
n = 3200)
rl <- rtweet::rate_limit("get_timeline")
print(paste0("Index: ", index,
"Scraped ", nrow(df),
" tweets. Remaining: ", rl[["remaining"]]))
Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# print(df)
df
}
l_tls <-
spliced_list %>%
imap(~load_slowly(.x, .y))
# if (save_res == TRUE) {
#   save_name <- paste0(df_main_status$screen_name,
#                       "_",
#                       str_sub(df_main_status$text, end = 15),
#                       "_tls.rds")
#   saveRDS(l_tls, save_name)
# }
l_tls %>% bind_rows()
}
scrape_timelines <- function(thread_ids, save_res = TRUE) {
safe_tl <- purrr::possibly(rtweet::get_timelines, otherwise = tibble())
# l <- vector("list", length(thread_ids))
# for (i in 1:length(l)) {
#   rl <- rtweet::rate_limit("get_timeline")
#   if (rl[["remaining"]] <= 2) {
#     print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#     Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
#   }
#   l[[i]] <- safe_tl(thread_ids[[i]], n = 3200, since_id = main_status_id)
#   print(paste0("Index: ", i,
#                "; Scraped ", nrow(l[[i]]),
#                " tweets. Remaining: ", rl[["remaining"]]))
# }
# df_favs <- l %>% dplyr::bind_rows()
# # if (save_res == TRUE) {
# #   save_name <- paste0(df_main_status$screen_name,
# #                       "_",
# #                       str_sub(df_main_status$text, end = 15),
# #                       "_favs.rds")
# #   saveRDS(df_favs, save_name)
# # }
# df_favs
rl <- rtweet::rate_limit("get_timeline")
# if (rl[["remaining"]] != 900) Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
spliced_list <-
seq(0, length(thread_ids), 175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
# if (rl[["remaining"]] <= 2) {
#   print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#   Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# }
load_slowly <- function(thread_ids, index) {
df <- safe_tl(thread_ids,
since_id = main_status_id,
n = 3200)
rl <- rtweet::rate_limit("get_timeline")
print(paste0("Index: ", index,
"Scraped ", nrow(df),
" tweets. Remaining: ", rl[["remaining"]]))
Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# print(df)
df
}
l_tls <-
spliced_list %>%
imap(~load_slowly(.x, .y))
# if (save_res == TRUE) {
#   save_name <- paste0(df_main_status$screen_name,
#                       "_",
#                       str_sub(df_main_status$text, end = 15),
#                       "_tls.rds")
#   saveRDS(l_tls, save_name)
# }
l_tls %>% bind_rows()
}
aa <- scrape_timelines(thread_ids[1:176])
as.numeric(rl[["reset"]], "secs") + 1
traceback()
possibly(rtweet::rate_limit("get_timeline"))
possibly(rtweet::rate_limit)
possibly(rtweet::rate_limit, otherwise = tibble(reset = 900))
ww <- possibly(rtweet::rate_limit, otherwise = tibble(reset = 900))
ww("get_timeline")
ww("get_timelin")
rl <- rtweet::rate_limit("get_timeline")
rl
ww <- data.frame()
ww$reset
ww$reset == 900
tryCatch(rtweet::rate_limit("kuk"), warningCondition("lkulu"))
tryCatch(rtweet::rate_limit("kuk"), warningCondition("lkulu"), finally = "jyg")
tryCatch(rtweet::rate_limit("kuk"), warningCondition("Rate limit exceeded - 88"), finally = "jyg")
rtweet::rate_limit("kuk")
rl <- rtweet::rate_limit("get_timeline")
rl
scrape_timelines <- function(thread_ids, save_res = TRUE) {
safe_tl <- purrr::possibly(rtweet::get_timelines, otherwise = tibble())
# l <- vector("list", length(thread_ids))
# for (i in 1:length(l)) {
#   rl <- rtweet::rate_limit("get_timeline")
#   if (rl[["remaining"]] <= 2) {
#     print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#     Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
#   }
#   l[[i]] <- safe_tl(thread_ids[[i]], n = 3200, since_id = main_status_id)
#   print(paste0("Index: ", i,
#                "; Scraped ", nrow(l[[i]]),
#                " tweets. Remaining: ", rl[["remaining"]]))
# }
# df_favs <- l %>% dplyr::bind_rows()
# # if (save_res == TRUE) {
# #   save_name <- paste0(df_main_status$screen_name,
# #                       "_",
# #                       str_sub(df_main_status$text, end = 15),
# #                       "_favs.rds")
# #   saveRDS(df_favs, save_name)
# # }
# df_favs
rl <- rtweet::rate_limit("get_timeline")
if (rl[["remaining"]] != 900) Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
spliced_list <-
seq(0, length(thread_ids), 175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
# if (rl[["remaining"]] <= 2) {
#   print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#   Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# }
load_slowly <- function(thread_ids, index) {
rl <- rtweet::rate_limit("get_timeline")
df <- safe_tl(thread_ids,
since_id = main_status_id,
n = 3200)
print(paste0("Index: ", index,
"Scraped ", nrow(df),
" tweets. Remaining: ", rl[["remaining"]]))
Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# print(df)
df
}
l_tls <-
spliced_list %>%
imap(~load_slowly(.x, .y))
# if (save_res == TRUE) {
#   save_name <- paste0(df_main_status$screen_name,
#                       "_",
#                       str_sub(df_main_status$text, end = 15),
#                       "_tls.rds")
#   saveRDS(l_tls, save_name)
# }
l_tls %>% bind_rows()
}
scrape_timelines <- function(thread_ids, save_res = TRUE) {
safe_tl <- purrr::possibly(rtweet::get_timelines, otherwise = tibble())
# l <- vector("list", length(thread_ids))
# for (i in 1:length(l)) {
#   rl <- rtweet::rate_limit("get_timeline")
#   if (rl[["remaining"]] <= 2) {
#     print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#     Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
#   }
#   l[[i]] <- safe_tl(thread_ids[[i]], n = 3200, since_id = main_status_id)
#   print(paste0("Index: ", i,
#                "; Scraped ", nrow(l[[i]]),
#                " tweets. Remaining: ", rl[["remaining"]]))
# }
# df_favs <- l %>% dplyr::bind_rows()
# # if (save_res == TRUE) {
# #   save_name <- paste0(df_main_status$screen_name,
# #                       "_",
# #                       str_sub(df_main_status$text, end = 15),
# #                       "_favs.rds")
# #   saveRDS(df_favs, save_name)
# # }
# df_favs
rl <- rtweet::rate_limit("get_timeline")
if (rl[["remaining"]] != 900) Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
spliced_list <-
seq(0, length(thread_ids), 175) %>%
map(~.x + 1:175) %>%
map(~thread_ids[.x] %>%
na.omit() %>%
as.character())
# if (rl[["remaining"]] <= 2) {
#   print(paste0("Rate limit reached. Resuming at ", rl[["reset_at"]]))
#   Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# }
load_slowly <- function(thread_ids, index) {
rl <- rtweet::rate_limit("get_timeline")
df <- safe_tl(thread_ids,
since_id = main_status_id,
n = 3200)
print(paste0("Index: ", index,
" of ", length(spliced_list),
"; Scraped ", nrow(df),
" tweets. Remaining: ", rl[["remaining"]]))
Sys.sleep(as.numeric(rl[["reset"]], "secs") + 1)
# print(df)
df
}
l_tls <-
spliced_list %>%
imap(~load_slowly(.x, .y))
# if (save_res == TRUE) {
#   save_name <- paste0(df_main_status$screen_name,
#                       "_",
#                       str_sub(df_main_status$text, end = 15),
#                       "_tls.rds")
#   saveRDS(l_tls, save_name)
# }
l_tls %>% bind_rows()
}
rl <- rtweet::rate_limit("get_timeline")
rl
aa <- scrape_timelines(thread_ids[1:176])
print(paste0("Downloaded bulk ", index,
" of ", length(spliced_list),
"; Scraped ", nrow(df),
" tweets. Resuming at: ", rl[["reset_at"]]))
index <- 1
print(paste0("Downloaded bulk ", index,
" of ", length(spliced_list),
"; Scraped ", nrow(df),
" tweets. Resuming at: ", rl[["reset_at"]]))
rl <- rtweet::rate_limit("get_favorites")
rl
rl <- rtweet::rate_limit("search_tweet")
rl <- rtweet::rate_limit("get_favorites")
rl <- rtweet::rate_limit("search_tweets")
rl
rl <- rtweet::rate_limit()
rl
View(rl)
rl <- rtweet::rate_limit()
rl[rl$query == "application/rate_limit_status"]
rl[rl$query == "application/rate_limit_status",]
rl[rl$query == "application/rate_limit_status","remaining"]
rl[rl$query == "favorites/list","remaining"]
rl[[rl$query == "favorites/list","remaining"]]
rl[rl$query == "favorites/list",][["remaining"]]
rl[rl$query == "statuses/user_timeline"][["remaining"]] != 900 |
rl[rl$query == "favorites/list",][["remaining"]] != 75
rl[rl$query == "statuses/user_timeline"][["remaining"]] != 900 | rl[rl$query == "favorites/list",][["remaining"]] != 75
rl[rl$query == "statuses/user_timeline"][["remaining"]]
rl[rl$query == "statuses/user_timeline",][["remaining"]] != 900 |
rl[rl$query == "favorites/list",][["remaining"]] != 75
rl[rl$query == "statuses/user_timeline",][["remaining"]]
as.numeric(rl[1,][["reset"]], "secs") + 1
library(threadnet)
devtools::check()
devtools::install()
