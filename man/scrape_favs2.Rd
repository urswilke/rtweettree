% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scraping.R
\name{scrape_favs2}
\alias{scrape_favs2}
\title{Scrape all likes of all users occurring in a thread of a twitter status_id}
\usage{
scrape_favs2(ids, save_res = TRUE)
}
\arguments{
\item{ids}{Vector of all code{user_id}s}

\item{save_res}{logical if file should be saved}
}
\value{
Dataframe of all timelines of all \code{thread_ids}
}
\description{
Scrape all likes of all users occurring in a thread of a twitter status_id
}
\examples{
main_status_id <- "1234620900386975744"
df_main_status <- rtweet::lookup_statuses(main_status_id)
df_thread <- search_thread(main_status_id)
thread_ids <- df_thread$user_id \%>\% unique()
df_tls <- scrape_timelines(thread_ids)
df0 <- df_main_status \%>\%
                       dplyr::filter(status_id == main_status_id) \%>\%
                       dplyr::select(to = status_id, user_id) \%>\%
                       dplyr::mutate(from = "root", type = "root")
tweet_edges <-
find_connections_rec(dplyr::bind_rows(df_thread, df_tls), df0)
ids <- tweet_edges$user_id \%>\% unique()
df_favs <- scrape_favs2(ids)
}
